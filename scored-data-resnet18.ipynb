{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# !pip install transformers\nimport sys\nsys.path.append('../input/bird-filter-data/noisereduce')\nimport noisereduce as nr","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-05-10T07:09:13.472765Z","iopub.execute_input":"2022-05-10T07:09:13.473442Z","iopub.status.idle":"2022-05-10T07:09:13.479482Z","shell.execute_reply.started":"2022-05-10T07:09:13.473406Z","shell.execute_reply":"2022-05-10T07:09:13.478683Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport numpy as np\nimport random\nimport os\nclass config:\n    num_fold = 10\n    sample_rate= 32_000\n    sampleNum = 32_000*5\n    n_fft=1024\n    win_length = 1024\n    hop_length=512\n    n_mels=64\n    duration=5\n    num_classes = 22\n    train_batch_size = 32\n    valid_batch_size = 32\n    epochs = 20\n    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n    learning_rate = 5e-5\n    \nconfig.device","metadata":{"execution":{"iopub.status.busy":"2022-05-10T07:09:13.485063Z","iopub.execute_input":"2022-05-10T07:09:13.485505Z","iopub.status.idle":"2022-05-10T07:09:13.494659Z","shell.execute_reply.started":"2022-05-10T07:09:13.485476Z","shell.execute_reply":"2022-05-10T07:09:13.493606Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport os\nPATH_TRAIN_DATASET = \"../input/scorebirddata/\"\npath_csv = os.path.join(PATH_TRAIN_DATASET, \"Filter_Clip_Major_Score_Data.csv\")\ntrain_meta = pd.read_csv(path_csv)\ntrain_meta","metadata":{"execution":{"iopub.status.busy":"2022-05-10T07:09:13.504483Z","iopub.execute_input":"2022-05-10T07:09:13.504669Z","iopub.status.idle":"2022-05-10T07:09:13.544759Z","shell.execute_reply.started":"2022-05-10T07:09:13.504647Z","shell.execute_reply":"2022-05-10T07:09:13.544118Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train_meta = train_meta.dropna().reset_index(drop=True)\n\ntrain_meta['new_filename'] = train_meta['filename'].str.replace('.ogg', '_') + train_meta['seg_index'].values.astype(int).astype(str) +'.ogg' ","metadata":{"execution":{"iopub.status.busy":"2022-05-10T07:09:13.546572Z","iopub.execute_input":"2022-05-10T07:09:13.546855Z","iopub.status.idle":"2022-05-10T07:09:13.569741Z","shell.execute_reply.started":"2022-05-10T07:09:13.54682Z","shell.execute_reply":"2022-05-10T07:09:13.568953Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_meta['new_filename'].str.len().max()","metadata":{"execution":{"iopub.status.busy":"2022-05-10T07:09:13.571037Z","iopub.execute_input":"2022-05-10T07:09:13.571277Z","iopub.status.idle":"2022-05-10T07:09:13.582479Z","shell.execute_reply.started":"2022-05-10T07:09:13.571246Z","shell.execute_reply":"2022-05-10T07:09:13.581775Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import json\n\nwith open('../input/birdclef-2022/scored_birds.json') as fp:\n    scored_birds = json.load(fp)\n\nprint(scored_birds)","metadata":{"execution":{"iopub.status.busy":"2022-05-10T07:09:13.584803Z","iopub.execute_input":"2022-05-10T07:09:13.585271Z","iopub.status.idle":"2022-05-10T07:09:13.594386Z","shell.execute_reply.started":"2022-05-10T07:09:13.585235Z","shell.execute_reply":"2022-05-10T07:09:13.593503Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"index = train_meta[~train_meta['primary_label'].isin(scored_birds)]['primary_label'].index\nindex","metadata":{"execution":{"iopub.status.busy":"2022-05-10T07:09:13.595762Z","iopub.execute_input":"2022-05-10T07:09:13.596009Z","iopub.status.idle":"2022-05-10T07:09:13.608528Z","shell.execute_reply.started":"2022-05-10T07:09:13.595976Z","shell.execute_reply":"2022-05-10T07:09:13.607677Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in index:\n    train_meta.iloc[i,0]='others'","metadata":{"execution":{"iopub.status.busy":"2022-05-10T07:09:13.610213Z","iopub.execute_input":"2022-05-10T07:09:13.610391Z","iopub.status.idle":"2022-05-10T07:09:13.770029Z","shell.execute_reply.started":"2022-05-10T07:09:13.610369Z","shell.execute_reply":"2022-05-10T07:09:13.769239Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_meta","metadata":{"execution":{"iopub.status.busy":"2022-05-10T07:09:13.773085Z","iopub.execute_input":"2022-05-10T07:09:13.773441Z","iopub.status.idle":"2022-05-10T07:09:13.803301Z","shell.execute_reply.started":"2022-05-10T07:09:13.7734Z","shell.execute_reply":"2022-05-10T07:09:13.802593Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\n\nencoder = LabelEncoder()\ntrain_meta['primary_label_encoded'] = encoder.fit_transform(train_meta['primary_label'])","metadata":{"execution":{"iopub.status.busy":"2022-05-10T07:09:13.804447Z","iopub.execute_input":"2022-05-10T07:09:13.804679Z","iopub.status.idle":"2022-05-10T07:09:13.811497Z","shell.execute_reply.started":"2022-05-10T07:09:13.804647Z","shell.execute_reply":"2022-05-10T07:09:13.810666Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"encoder.classes_","metadata":{"execution":{"iopub.status.busy":"2022-05-10T07:09:13.813807Z","iopub.execute_input":"2022-05-10T07:09:13.814668Z","iopub.status.idle":"2022-05-10T07:09:13.821263Z","shell.execute_reply.started":"2022-05-10T07:09:13.814633Z","shell.execute_reply":"2022-05-10T07:09:13.820411Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# save encoder","metadata":{}},{"cell_type":"code","source":"np.save('encoder_list.npy',encoder.classes_)\n","metadata":{"execution":{"iopub.status.busy":"2022-05-10T07:09:13.822485Z","iopub.execute_input":"2022-05-10T07:09:13.822909Z","iopub.status.idle":"2022-05-10T07:09:13.829834Z","shell.execute_reply.started":"2022-05-10T07:09:13.822874Z","shell.execute_reply":"2022-05-10T07:09:13.82921Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import StratifiedKFold\n\nskf = StratifiedKFold(n_splits=config.num_fold)\nfor k, (_, val_ind) in enumerate(skf.split(X=train_meta, y=train_meta['primary_label_encoded'])):\n    train_meta.loc[val_ind, 'fold'] = k","metadata":{"execution":{"iopub.status.busy":"2022-05-10T07:09:13.831027Z","iopub.execute_input":"2022-05-10T07:09:13.831269Z","iopub.status.idle":"2022-05-10T07:09:13.849875Z","shell.execute_reply.started":"2022-05-10T07:09:13.831235Z","shell.execute_reply":"2022-05-10T07:09:13.8492Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_data(df,fold):\n    train_df = df[~df['fold'].isin(fold)].reset_index(drop=True)\n    valid_df = df[df['fold'].isin(fold)].reset_index(drop=True)\n    return train_df,valid_df  \ntrain_df,valid_df = get_data(train_meta,[7,8,9])","metadata":{"execution":{"iopub.status.busy":"2022-05-10T07:09:13.850859Z","iopub.execute_input":"2022-05-10T07:09:13.851427Z","iopub.status.idle":"2022-05-10T07:09:13.860867Z","shell.execute_reply.started":"2022-05-10T07:09:13.85139Z","shell.execute_reply":"2022-05-10T07:09:13.860114Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"valid_df[['primary_label','filename']].groupby('primary_label').count().describe()","metadata":{"execution":{"iopub.status.busy":"2022-05-10T07:09:13.862128Z","iopub.execute_input":"2022-05-10T07:09:13.862759Z","iopub.status.idle":"2022-05-10T07:09:13.881019Z","shell.execute_reply.started":"2022-05-10T07:09:13.862703Z","shell.execute_reply":"2022-05-10T07:09:13.880394Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df[['primary_label','filename']].groupby('primary_label').count().describe()","metadata":{"execution":{"iopub.status.busy":"2022-05-10T07:09:13.882349Z","iopub.execute_input":"2022-05-10T07:09:13.882706Z","iopub.status.idle":"2022-05-10T07:09:13.898175Z","shell.execute_reply.started":"2022-05-10T07:09:13.882672Z","shell.execute_reply":"2022-05-10T07:09:13.897412Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torchaudio\n# STFT\nn_fft = 1024\nwin_length = 1024\nhop_length = 512\ntransform = torchaudio.transforms.Spectrogram(\n    n_fft = n_fft,           # freqGroup = n_fft//2 + 1\n    win_length = win_length, # freq gap for each group\n    hop_length = hop_length, # length = samples / hop_length\n    center = True,\n    pad_mode = 'reflect',\n    power=2.0\n).to('cpu')\ntransform","metadata":{"execution":{"iopub.status.busy":"2022-05-10T07:09:13.89934Z","iopub.execute_input":"2022-05-10T07:09:13.899649Z","iopub.status.idle":"2022-05-10T07:09:14.013283Z","shell.execute_reply.started":"2022-05-10T07:09:13.899613Z","shell.execute_reply":"2022-05-10T07:09:14.012602Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"transform = torchaudio.transforms.MFCC(\n    sample_rate = 32000, \n    n_mfcc = 128, \n    dct_type = 2, \n    norm = 'ortho', \n    log_mels = False, \n)\ntransform","metadata":{"execution":{"iopub.status.busy":"2022-05-10T07:09:14.014357Z","iopub.execute_input":"2022-05-10T07:09:14.014575Z","iopub.status.idle":"2022-05-10T07:09:14.055209Z","shell.execute_reply.started":"2022-05-10T07:09:14.014541Z","shell.execute_reply":"2022-05-10T07:09:14.054561Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#!pip install noisereduce\nfrom torch.utils.data import Dataset, DataLoader\nimport noisereduce as nr\nimport torchaudio\nimport random\nimport numpy as np\nclass BirdClefDataset(Dataset):\n    def __init__(self, df):\n        self.audio_paths = df['new_filename'].values\n        self.labels = df['primary_label_encoded'].values\n        self.stretch = torchaudio.transforms.TimeStretch()\n        self.sr = 32000\n    def __len__(self):\n        return len(self.audio_paths)\n    \n    def __getitem__(self, index):\n        filename = os.path.join(PATH_TRAIN_DATASET, 'Slice_data_score',self.audio_paths[index])\n        waveform0,_ = torchaudio.load(filename)\n        waveform=nr.reduce_noise(y=waveform0, sr=self.sr)\n        waveform=torch.from_numpy(waveform)\n        #waveform=torch.from_numpy(waveform2)\n       \n        splitPoint = random.randint(self.sr,self.sr*4)\n        newWaveform=torch.cat([waveform[:,splitPoint:],waveform[:,:splitPoint]],dim=1)\n        label = torch.tensor(self.labels[index])\n        \n        return transform(newWaveform), label","metadata":{"execution":{"iopub.status.busy":"2022-05-10T07:09:14.056467Z","iopub.execute_input":"2022-05-10T07:09:14.056931Z","iopub.status.idle":"2022-05-10T07:09:14.067194Z","shell.execute_reply.started":"2022-05-10T07:09:14.056895Z","shell.execute_reply":"2022-05-10T07:09:14.066329Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch.nn as nn\nimport torch.nn.functional as F\n#from transformers import Wav2Vec2ForSequenceClassification\n","metadata":{"execution":{"iopub.status.busy":"2022-05-10T07:09:14.068795Z","iopub.execute_input":"2022-05-10T07:09:14.069043Z","iopub.status.idle":"2022-05-10T07:09:14.076121Z","shell.execute_reply.started":"2022-05-10T07:09:14.069009Z","shell.execute_reply":"2022-05-10T07:09:14.075398Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def loss_fn(outputs, labels):\n    return nn.CrossEntropyLoss()(outputs, labels)","metadata":{"execution":{"iopub.status.busy":"2022-05-10T01:20:01.678499Z","iopub.execute_input":"2022-05-10T01:20:01.679036Z","iopub.status.idle":"2022-05-10T01:20:01.690152Z","shell.execute_reply.started":"2022-05-10T01:20:01.678992Z","shell.execute_reply":"2022-05-10T01:20:01.689007Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import f1_score\n\ndef train(model, data_loader, optimizer, scheduler, device, epoch):\n    model.train()\n    pred = []\n    label = []\n    \n    running_loss = 0\n    acc = 0\n    loop = tqdm(data_loader, position=0)\n    for i, (spec, labels) in enumerate(loop):\n        spec = spec.to(device)\n        labels = labels.to(device)\n        \n        outputs = model(spec)\n        _, preds = torch.max(outputs, 1)\n        acc += (preds==labels).sum()\n        \n        loss = loss_fn(outputs, labels)\n        \n        loss.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n        \n        if scheduler is not None:\n            scheduler.step()\n            \n        running_loss += loss.item()\n        pred.extend(preds.view(-1).cpu().detach().numpy())\n        label.extend(labels.view(-1).cpu().detach().numpy())\n        \n        loop.set_description(f\"Epoch [{epoch+1}/{config.epochs}]\")\n        loop.set_postfix(loss=loss.item())\n\n    return running_loss/len(data_loader),acc/(len(data_loader)*config.train_batch_size)","metadata":{"execution":{"iopub.status.busy":"2022-05-10T01:20:01.692671Z","iopub.execute_input":"2022-05-10T01:20:01.693843Z","iopub.status.idle":"2022-05-10T01:20:01.714411Z","shell.execute_reply.started":"2022-05-10T01:20:01.693798Z","shell.execute_reply":"2022-05-10T01:20:01.713505Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def valid(model, data_loader, device, epoch):\n    model.eval()\n    \n    acc = 0\n    running_loss = 0\n    pred = []\n    label = []\n\n    loop = tqdm(data_loader, position=0)\n    for spec, labels in loop:\n        spec = spec.to(device)\n        labels = labels.to(device)\n        \n        outputs = model(spec)\n        _, preds = torch.max(outputs, 1)\n        acc += (preds==labels).sum()\n        \n        loss = loss_fn(outputs, labels)\n            \n        running_loss += loss.item()\n        \n        pred.extend(preds.view(-1).cpu().detach().numpy())\n        label.extend(labels.view(-1).cpu().detach().numpy())\n        \n        loop.set_description(f\"Epoch [{epoch+1}/{config.epochs}]\")\n        loop.set_postfix(loss=loss.item())\n        \n    valid_f1 = f1_score(label, pred, average='macro')\n    \n    return running_loss/len(data_loader), valid_f1,acc/(len(data_loader)*config.valid_batch_size)","metadata":{"execution":{"iopub.status.busy":"2022-05-10T01:20:01.720509Z","iopub.execute_input":"2022-05-10T01:20:01.723506Z","iopub.status.idle":"2022-05-10T01:20:01.737781Z","shell.execute_reply.started":"2022-05-10T01:20:01.723454Z","shell.execute_reply":"2022-05-10T01:20:01.736619Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataset = BirdClefDataset(train_df)\nvalid_dataset = BirdClefDataset(valid_df)\n\ntrain_loader = torch.utils.data.DataLoader(train_dataset, batch_size=config.train_batch_size, shuffle=True,num_workers=os.cpu_count(),pin_memory=(torch.cuda.is_available()))\nvalid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=config.valid_batch_size, shuffle=True,num_workers=os.cpu_count(),pin_memory=(torch.cuda.is_available()))","metadata":{"execution":{"iopub.status.busy":"2022-05-10T01:20:01.744273Z","iopub.execute_input":"2022-05-10T01:20:01.746632Z","iopub.status.idle":"2022-05-10T01:20:01.757699Z","shell.execute_reply.started":"2022-05-10T01:20:01.746588Z","shell.execute_reply":"2022-05-10T01:20:01.756783Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#import torch\n#import torchvision.models as models\n#import torch.nn as nn\n#class Net(nn.Module):\n#    def __init__(self, model):\n#        super(Net, self).__init__()\n#        #self.conv1= nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3,bias=False)\n#        # 取掉model的后1层\n#        self.resnet_layer = nn.Sequential(*list(model.children())[:-1])\n#        self.Linear_layer = nn.Linear(512, 22) #加上一层参数修改好的全连接层\n# \n#    def forward(self, x):\n#        x = self.resnet_layer(x)\n#        x = x.view(x.size(0), -1)\n#        x = self.Linear_layer(x)\n#        return x\n#resnet = models.resnet18(pretrained=True)\n#resnet.conv1= nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3,bias=False)\n#model = Net(resnet)\n##print(model.conv1)\n#print(model)","metadata":{"execution":{"iopub.status.busy":"2022-05-10T01:20:01.763237Z","iopub.execute_input":"2022-05-10T01:20:01.76609Z","iopub.status.idle":"2022-05-10T01:20:01.77299Z","shell.execute_reply.started":"2022-05-10T01:20:01.766021Z","shell.execute_reply":"2022-05-10T01:20:01.772123Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch.nn as nn\nimport torch.utils.model_zoo as model_zoo\n__all__ = ['ResNet', 'resnet18', 'resnet34', 'resnet50', 'resnet101',\n           'resnet152']\n \nmodel_urls = {\n    'resnet18': '../input/weight1/resnet18-5c106cde.pth'\n}\ndef conv3x3(in_planes, out_planes, stride=1):\n    \"\"\"3x3 convolution with padding\"\"\"\n    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n                     padding=1, bias=False)\n \ndef conv1x1(in_planes, out_planes, stride=1):\n    \"\"\"1x1 convolution\"\"\"\n    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)\nclass BasicBlock(nn.Module):\n    expansion = 1\n \n    def __init__(self, inplanes, planes, stride=1, downsample=None):\n        super(BasicBlock, self).__init__()\n        self.conv1 = conv3x3(inplanes, planes, stride)\n        self.bn1 = nn.BatchNorm2d(planes)\n        self.relu = nn.ReLU(inplace=True)\n        self.conv2 = conv3x3(planes, planes)\n        self.bn2 = nn.BatchNorm2d(planes)\n        self.downsample = downsample\n        self.stride = stride\n \n    def forward(self, x):\n        identity = x\n \n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n \n        out = self.conv2(out)\n        out = self.bn2(out)\n \n        if self.downsample is not None:\n            identity = self.downsample(x)\n \n        out += identity\n        out = self.relu(out)\n \n        return out\nclass Bottleneck(nn.Module):\n    expansion = 4\n \n    def __init__(self, inplanes, planes, stride=1, downsample=None):\n        super(Bottleneck, self).__init__()\n        self.conv1 = conv1x1(inplanes, planes)\n        self.bn1 = nn.BatchNorm2d(planes)\n        self.conv2 = conv3x3(planes, planes, stride)\n        self.bn2 = nn.BatchNorm2d(planes)\n        self.conv3 = conv1x1(planes, planes * self.expansion)\n        self.bn3 = nn.BatchNorm2d(planes * self.expansion)\n        self.relu = nn.ReLU(inplace=True)\n        self.downsample = downsample\n        self.stride = stride\n \n    def forward(self, x):\n        identity = x\n \n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n \n        out = self.conv2(out)\n        out = self.bn2(out)\n        out = self.relu(out)\n \n        out = self.conv3(out)\n        out = self.bn3(out)\n \n        if self.downsample is not None:\n            identity = self.downsample(x)\n \n        out += identity\n        out = self.relu(out)\n \n        return out\n\n\nclass ResNet(nn.Module):\n \n    def __init__(self, block, layers, num_classes=22, zero_init_residual=False):\n        super(ResNet, self).__init__()\n        self.inplanes = 64\n        self.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3,\n                               bias=False)\n        self.bn1 = nn.BatchNorm2d(64)\n        self.relu = nn.ReLU(inplace=True)\n        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n        self.layer1 = self._make_layer(block, 64, layers[0])\n        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n        self.fc = nn.Linear(512 * block.expansion, num_classes)\n \n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n            elif isinstance(m, nn.BatchNorm2d):\n                nn.init.constant_(m.weight, 1)\n                nn.init.constant_(m.bias, 0)\n \n        # Zero-initialize the last BN in each residual branch,\n        # so that the residual branch starts with zeros, and each residual block behaves like an identity.\n        # This improves the model by 0.2~0.3% according to https://arxiv.org/abs/1706.02677\n        if zero_init_residual:\n            for m in self.modules():\n                if isinstance(m, Bottleneck):\n                    nn.init.constant_(m.bn3.weight, 0)\n                elif isinstance(m, BasicBlock):\n                    nn.init.constant_(m.bn2.weight, 0)\n \n    def _make_layer(self, block, planes, blocks, stride=1):\n        downsample = None\n        if stride != 1 or self.inplanes != planes * block.expansion:\n            downsample = nn.Sequential(\n                conv1x1(self.inplanes, planes * block.expansion, stride),\n                nn.BatchNorm2d(planes * block.expansion),\n            )\n \n        layers = []\n        layers.append(block(self.inplanes, planes, stride, downsample))\n        self.inplanes = planes * block.expansion\n        for _ in range(1, blocks):\n            layers.append(block(self.inplanes, planes))\n \n        return nn.Sequential(*layers)\n \n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.bn1(x)\n        x = self.relu(x)\n        x = self.maxpool(x)\n \n        x = self.layer1(x)\n        x = self.layer2(x)\n        x = self.layer3(x)\n        x = self.layer4(x)\n \n        x = self.avgpool(x)\n        x = x.view(x.size(0), -1)\n        x = self.fc(x)\n \n        return x\n\n\ndef resnet18(pretrained=False, **kwargs):\n    \"\"\"Constructs a ResNet-18 model.\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    \"\"\"\n    model = ResNet(BasicBlock, [2, 2, 2, 2], **kwargs).to(config.device)\n    if pretrained:\n        model.load_state_dict(model_zoo.load_url(model_urls['resnet18']))\n    return model\n\nmodel=resnet18().to(config.device)\n#print(model)","metadata":{"execution":{"iopub.status.busy":"2022-05-10T07:08:31.714168Z","iopub.execute_input":"2022-05-10T07:08:31.71458Z","iopub.status.idle":"2022-05-10T07:08:34.668418Z","shell.execute_reply.started":"2022-05-10T07:08:31.714535Z","shell.execute_reply":"2022-05-10T07:08:34.667652Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tqdm import tqdm\n \n# from transformers import Wav2Vec2Model, Wav2Vec2Config\n\n# configuration = Wav2Vec2Config(num_labels=config.num_classes)\n# model = Wav2Vec2ForSequenceClassification(configuration)\n\n\n# PATH_Model = \"../input/model-02f1\"\n# model_path = os.path.join(PATH_Model, \"model.pt\")\n# model = BirdClefModel()\n# model.load_state_dict(torch.load(model_path,map_location='cpu'))\n\n\noptimizer = torch.optim.Adam(model.parameters(), lr=5e-5)\nscheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, eta_min=1e-5, T_max=5)\n\nfor epoch in range(20):\n    train_loss,train_acc = train(model, train_loader, optimizer, scheduler, config.device, epoch)\n    valid_loss, valid_f1,valid_acc = valid(model, valid_loader, config.device, epoch)\n    print('train Loss: ',train_loss,'train_acc: ',train_acc.item(),'valid Loss: ',valid_loss,'valid_acc: ',valid_acc.item(),\" vaild_F1\",valid_f1)","metadata":{"execution":{"iopub.status.busy":"2022-05-10T01:20:05.358486Z","iopub.execute_input":"2022-05-10T01:20:05.358956Z","iopub.status.idle":"2022-05-10T02:49:44.074537Z","shell.execute_reply.started":"2022-05-10T01:20:05.358863Z","shell.execute_reply":"2022-05-10T02:49:44.073775Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model","metadata":{"execution":{"iopub.status.busy":"2022-05-10T02:58:44.726907Z","iopub.execute_input":"2022-05-10T02:58:44.727644Z","iopub.status.idle":"2022-05-10T02:58:44.736586Z","shell.execute_reply.started":"2022-05-10T02:58:44.727606Z","shell.execute_reply":"2022-05-10T02:58:44.73574Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.save(model.state_dict(),\"model_20.pt\")\n","metadata":{"execution":{"iopub.status.busy":"2022-05-10T07:10:08.014118Z","iopub.execute_input":"2022-05-10T07:10:08.014372Z","iopub.status.idle":"2022-05-10T07:10:08.12536Z","shell.execute_reply.started":"2022-05-10T07:10:08.014343Z","shell.execute_reply":"2022-05-10T07:10:08.124422Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.save(model,'model_20.pth')","metadata":{"execution":{"iopub.status.busy":"2022-05-10T07:10:26.358621Z","iopub.execute_input":"2022-05-10T07:10:26.35941Z","iopub.status.idle":"2022-05-10T07:10:26.43987Z","shell.execute_reply.started":"2022-05-10T07:10:26.359373Z","shell.execute_reply":"2022-05-10T07:10:26.439086Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = torch.load('../input/rennet18/model_20.pth')","metadata":{"execution":{"iopub.status.busy":"2022-05-10T07:10:04.803418Z","iopub.execute_input":"2022-05-10T07:10:04.803681Z","iopub.status.idle":"2022-05-10T07:10:04.849089Z","shell.execute_reply.started":"2022-05-10T07:10:04.803652Z","shell.execute_reply":"2022-05-10T07:10:04.848355Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}