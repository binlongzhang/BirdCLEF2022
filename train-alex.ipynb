{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# !pip install transformers\nimport sys\nsys.path.append('../input/bird-filter-data')\nimport noisereduce as nr","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-05-05T10:08:19.385717Z","iopub.execute_input":"2022-05-05T10:08:19.386068Z","iopub.status.idle":"2022-05-05T10:08:19.423364Z","shell.execute_reply.started":"2022-05-05T10:08:19.385965Z","shell.execute_reply":"2022-05-05T10:08:19.422686Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import torch\nimport numpy as np\nimport random\nimport os\nclass config:\n    num_fold = 10\n    sample_rate= 32_000\n    sampleNum = 32_000*5\n    n_fft=1024\n    win_length = 1024\n    hop_length=512\n    n_mels=64\n    duration=5\n    num_classes = 152\n    train_batch_size = 128\n    valid_batch_size = 128\n    epochs = 5\n    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n    learning_rate = 1e-3\n    \nconfig.device","metadata":{"execution":{"iopub.status.busy":"2022-05-05T10:08:19.522100Z","iopub.execute_input":"2022-05-05T10:08:19.522570Z","iopub.status.idle":"2022-05-05T10:08:21.283580Z","shell.execute_reply.started":"2022-05-05T10:08:19.522538Z","shell.execute_reply":"2022-05-05T10:08:21.282895Z"},"trusted":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"'cuda'"},"metadata":{}}]},{"cell_type":"code","source":"import pandas as pd\nimport os\nPATH_TRAIN_DATASET = \"../input/bird-filter-data/Slice_data\"\npath_csv = os.path.join(PATH_TRAIN_DATASET, \"Filter_Clip_Data.csv\")\ntrain_meta = pd.read_csv(path_csv)\ntrain_meta.head()","metadata":{"execution":{"iopub.status.busy":"2022-05-05T10:08:21.285291Z","iopub.execute_input":"2022-05-05T10:08:21.285534Z","iopub.status.idle":"2022-05-05T10:08:21.480756Z","shell.execute_reply.started":"2022-05-05T10:08:21.285501Z","shell.execute_reply":"2022-05-05T10:08:21.480052Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"  primary_label                secondary_labels                     type  \\\n0       afrsil1                              []  ['call', 'flight call']   \n1       afrsil1                              []  ['call', 'flight call']   \n2       afrsil1  ['houspa', 'redava', 'zebdov']                 ['call']   \n3       afrsil1  ['houspa', 'redava', 'zebdov']                 ['call']   \n4       afrsil1  ['houspa', 'redava', 'zebdov']                 ['call']   \n\n   rating              filename   duration  segmentNum  seg_index  \n0     2.5  afrsil1/XC125458.ogg  11.102031         2.0        0.0  \n1     2.5  afrsil1/XC125458.ogg  11.102031         2.0        1.0  \n2     3.5  afrsil1/XC175522.ogg  47.020406         9.0        0.0  \n3     3.5  afrsil1/XC175522.ogg  47.020406         9.0        1.0  \n4     3.5  afrsil1/XC175522.ogg  47.020406         9.0        2.0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>primary_label</th>\n      <th>secondary_labels</th>\n      <th>type</th>\n      <th>rating</th>\n      <th>filename</th>\n      <th>duration</th>\n      <th>segmentNum</th>\n      <th>seg_index</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>afrsil1</td>\n      <td>[]</td>\n      <td>['call', 'flight call']</td>\n      <td>2.5</td>\n      <td>afrsil1/XC125458.ogg</td>\n      <td>11.102031</td>\n      <td>2.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>afrsil1</td>\n      <td>[]</td>\n      <td>['call', 'flight call']</td>\n      <td>2.5</td>\n      <td>afrsil1/XC125458.ogg</td>\n      <td>11.102031</td>\n      <td>2.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>afrsil1</td>\n      <td>['houspa', 'redava', 'zebdov']</td>\n      <td>['call']</td>\n      <td>3.5</td>\n      <td>afrsil1/XC175522.ogg</td>\n      <td>47.020406</td>\n      <td>9.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>afrsil1</td>\n      <td>['houspa', 'redava', 'zebdov']</td>\n      <td>['call']</td>\n      <td>3.5</td>\n      <td>afrsil1/XC175522.ogg</td>\n      <td>47.020406</td>\n      <td>9.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>afrsil1</td>\n      <td>['houspa', 'redava', 'zebdov']</td>\n      <td>['call']</td>\n      <td>3.5</td>\n      <td>afrsil1/XC175522.ogg</td>\n      <td>47.020406</td>\n      <td>9.0</td>\n      <td>2.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"train_meta = train_meta.dropna().reset_index(drop=True)\n\ntrain_meta['new_filename'] = train_meta['filename'].str.replace('.ogg', '_') + train_meta['seg_index'].values.astype(int).astype(str) +'.ogg' ","metadata":{"execution":{"iopub.status.busy":"2022-05-05T10:08:21.482029Z","iopub.execute_input":"2022-05-05T10:08:21.482419Z","iopub.status.idle":"2022-05-05T10:08:21.816291Z","shell.execute_reply.started":"2022-05-05T10:08:21.482383Z","shell.execute_reply":"2022-05-05T10:08:21.815577Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:3: FutureWarning: The default value of regex will change from True to False in a future version.\n  This is separate from the ipykernel package so we can avoid doing imports until\n","output_type":"stream"}]},{"cell_type":"code","source":"train_meta['new_filename'].str.len().max()","metadata":{"execution":{"iopub.status.busy":"2022-05-05T10:08:21.818276Z","iopub.execute_input":"2022-05-05T10:08:21.818603Z","iopub.status.idle":"2022-05-05T10:08:21.893076Z","shell.execute_reply.started":"2022-05-05T10:08:21.818564Z","shell.execute_reply":"2022-05-05T10:08:21.892274Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"24"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\n\nencoder = LabelEncoder()\ntrain_meta['primary_label_encoded'] = encoder.fit_transform(train_meta['primary_label'])","metadata":{"execution":{"iopub.status.busy":"2022-05-05T10:08:21.894555Z","iopub.execute_input":"2022-05-05T10:08:21.894811Z","iopub.status.idle":"2022-05-05T10:08:22.682190Z","shell.execute_reply.started":"2022-05-05T10:08:21.894776Z","shell.execute_reply":"2022-05-05T10:08:22.681442Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"# save encoder","metadata":{}},{"cell_type":"code","source":"np.save('encoder_list.npy',encoder.classes_)\n","metadata":{"execution":{"iopub.status.busy":"2022-05-05T10:08:22.684105Z","iopub.execute_input":"2022-05-05T10:08:22.684579Z","iopub.status.idle":"2022-05-05T10:08:22.689366Z","shell.execute_reply.started":"2022-05-05T10:08:22.684541Z","shell.execute_reply":"2022-05-05T10:08:22.688613Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import StratifiedKFold\n\nskf = StratifiedKFold(n_splits=config.num_fold)\nfor k, (_, val_ind) in enumerate(skf.split(X=train_meta, y=train_meta['primary_label_encoded'])):\n    train_meta.loc[val_ind, 'fold'] = k","metadata":{"execution":{"iopub.status.busy":"2022-05-05T10:08:22.690909Z","iopub.execute_input":"2022-05-05T10:08:22.691216Z","iopub.status.idle":"2022-05-05T10:08:22.784040Z","shell.execute_reply.started":"2022-05-05T10:08:22.691181Z","shell.execute_reply":"2022-05-05T10:08:22.783291Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_split.py:680: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=10.\n  UserWarning,\n","output_type":"stream"}]},{"cell_type":"code","source":"def get_data(df,fold):\n    train_df = df[~df['fold'].isin(fold)].reset_index(drop=True)\n    valid_df = df[df['fold'].isin(fold)].reset_index(drop=True)\n    return train_df,valid_df  \n\ntrain_df,valid_df = get_data(train_meta,[7,8,9])","metadata":{"execution":{"iopub.status.busy":"2022-05-05T10:08:22.785411Z","iopub.execute_input":"2022-05-05T10:08:22.785859Z","iopub.status.idle":"2022-05-05T10:08:22.828141Z","shell.execute_reply.started":"2022-05-05T10:08:22.785821Z","shell.execute_reply":"2022-05-05T10:08:22.827111Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"valid_df[['primary_label','filename']].groupby('primary_label').count().describe()\n","metadata":{"execution":{"iopub.status.busy":"2022-05-05T10:08:22.829694Z","iopub.execute_input":"2022-05-05T10:08:22.829962Z","iopub.status.idle":"2022-05-05T10:08:22.855160Z","shell.execute_reply.started":"2022-05-05T10:08:22.829926Z","shell.execute_reply":"2022-05-05T10:08:22.854347Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"          filename\ncount   152.000000\nmean    215.309211\nstd     276.315642\nmin       1.000000\n25%      31.750000\n50%      88.000000\n75%     300.000000\nmax    1191.000000","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>filename</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>152.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>215.309211</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>276.315642</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>31.750000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>88.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>300.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>1191.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"train_df[['primary_label','filename']].groupby('primary_label').count().describe()\n","metadata":{"execution":{"iopub.status.busy":"2022-05-05T10:08:22.858214Z","iopub.execute_input":"2022-05-05T10:08:22.858407Z","iopub.status.idle":"2022-05-05T10:08:22.886378Z","shell.execute_reply.started":"2022-05-05T10:08:22.858382Z","shell.execute_reply":"2022-05-05T10:08:22.885544Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"          filename\ncount   152.000000\nmean    502.407895\nstd     644.303067\nmin       1.000000\n25%      74.000000\n50%     205.500000\n75%     701.750000\nmax    2779.000000","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>filename</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>152.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>502.407895</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>644.303067</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>74.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>205.500000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>701.750000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>2779.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# filename = os.path.join(PATH_TRAIN_DATASET, 'Slice_data',train_df.iloc[0].new_filename)\n# waveform,_ = torchaudio.load(filename)","metadata":{"execution":{"iopub.status.busy":"2022-05-05T10:08:22.887819Z","iopub.execute_input":"2022-05-05T10:08:22.888088Z","iopub.status.idle":"2022-05-05T10:08:22.891813Z","shell.execute_reply.started":"2022-05-05T10:08:22.888054Z","shell.execute_reply":"2022-05-05T10:08:22.890924Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"import torchaudio\n# STFT\nn_fft = 1024\nwin_length = 1024\nhop_length = 512\ntransform = torchaudio.transforms.Spectrogram(\n    n_fft = n_fft,           # freqGroup = n_fft//2 + 1\n    win_length = win_length, # freq gap for each group\n    hop_length = hop_length, # length = samples / hop_length\n    center = True,\n    pad_mode = 'reflect',\n    power=2.0\n).to('cpu')\ntransform","metadata":{"execution":{"iopub.status.busy":"2022-05-05T10:08:22.893376Z","iopub.execute_input":"2022-05-05T10:08:22.893631Z","iopub.status.idle":"2022-05-05T10:08:23.064581Z","shell.execute_reply.started":"2022-05-05T10:08:22.893597Z","shell.execute_reply":"2022-05-05T10:08:23.063829Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"Spectrogram()"},"metadata":{}}]},{"cell_type":"code","source":"transform = torchaudio.transforms.MFCC(\n    sample_rate = 32000, \n    n_mfcc = 128, \n    dct_type = 2, \n    norm = 'ortho', \n    log_mels = False, \n)\ntransform","metadata":{"execution":{"iopub.status.busy":"2022-05-05T10:08:23.066001Z","iopub.execute_input":"2022-05-05T10:08:23.066410Z","iopub.status.idle":"2022-05-05T10:08:23.128639Z","shell.execute_reply.started":"2022-05-05T10:08:23.066375Z","shell.execute_reply":"2022-05-05T10:08:23.127938Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/torchaudio/functional/functional.py:433: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (128) may be set too high. Or, the value for `n_freqs` (201) may be set too low.\n  \"At least one mel filterbank has all zero values. \"\n","output_type":"stream"},{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"MFCC(\n  (amplitude_to_DB): AmplitudeToDB()\n  (MelSpectrogram): MelSpectrogram(\n    (spectrogram): Spectrogram()\n    (mel_scale): MelScale()\n  )\n)"},"metadata":{}}]},{"cell_type":"code","source":"# waveform,_ = torchaudio.load('../input/bird-filter-data/Slice_data/Slice_data/akekee/XC174953_0.ogg')\n# waveform.shape","metadata":{"execution":{"iopub.status.busy":"2022-05-05T10:08:23.129780Z","iopub.execute_input":"2022-05-05T10:08:23.130559Z","iopub.status.idle":"2022-05-05T10:08:23.134205Z","shell.execute_reply.started":"2022-05-05T10:08:23.130518Z","shell.execute_reply":"2022-05-05T10:08:23.133234Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"# spec = transform(waveform).unsqueeze(0)\n# spec","metadata":{"execution":{"iopub.status.busy":"2022-05-05T10:08:23.135386Z","iopub.execute_input":"2022-05-05T10:08:23.136137Z","iopub.status.idle":"2022-05-05T10:08:23.143187Z","shell.execute_reply.started":"2022-05-05T10:08:23.136098Z","shell.execute_reply":"2022-05-05T10:08:23.142411Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import Dataset, DataLoader\nimport torchaudio\nimport random\nclass BirdClefDataset(Dataset):\n    def __init__(self, df):\n        self.audio_paths = df['new_filename'].values\n        self.labels = df['primary_label_encoded'].values\n        self.stretch = torchaudio.transforms.TimeStretch()\n        self.sr = 32000\n    def __len__(self):\n        return len(self.audio_paths)\n    \n    def __getitem__(self, index):\n        filename = os.path.join(PATH_TRAIN_DATASET, 'Slice_data',self.audio_paths[index])\n        waveform,_ = torchaudio.load(filename)\n        splitPoint = random.randint(self.sr,self.sr*4)\n        newWaveform=torch.cat([waveform[:,splitPoint:],waveform[:,:splitPoint]],dim=1)\n        label = torch.tensor(self.labels[index])\n        \n        return transform(newWaveform), label","metadata":{"execution":{"iopub.status.busy":"2022-05-05T10:08:23.144317Z","iopub.execute_input":"2022-05-05T10:08:23.145213Z","iopub.status.idle":"2022-05-05T10:08:23.154954Z","shell.execute_reply.started":"2022-05-05T10:08:23.145174Z","shell.execute_reply":"2022-05-05T10:08:23.154155Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"import torch.nn as nn\nimport torch.nn.functional as F\n# from transformers import Wav2Vec2ForSequenceClassification\n","metadata":{"execution":{"iopub.status.busy":"2022-05-05T10:08:23.156822Z","iopub.execute_input":"2022-05-05T10:08:23.157231Z","iopub.status.idle":"2022-05-05T10:08:23.165540Z","shell.execute_reply.started":"2022-05-05T10:08:23.157193Z","shell.execute_reply":"2022-05-05T10:08:23.164764Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"def loss_fn(outputs, labels):\n    return nn.CrossEntropyLoss()(outputs, labels)","metadata":{"execution":{"iopub.status.busy":"2022-05-05T10:08:23.166569Z","iopub.execute_input":"2022-05-05T10:08:23.166765Z","iopub.status.idle":"2022-05-05T10:08:23.174675Z","shell.execute_reply.started":"2022-05-05T10:08:23.166742Z","shell.execute_reply":"2022-05-05T10:08:23.173884Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":"# Train","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import f1_score\n\ndef train(model, data_loader, optimizer, scheduler, device, epoch):\n    model.train()\n    pred = []\n    label = []\n    \n    running_loss = 0\n    acc = 0\n    loop = tqdm(data_loader, position=0)\n    for i, (spec, labels) in enumerate(loop):\n        spec = spec.to(device)\n        labels = labels.to(device)\n        \n        outputs = model(spec)\n        _, preds = torch.max(outputs, 1)\n        acc += (preds==labels).sum()\n        \n        loss = loss_fn(outputs, labels)\n        \n        loss.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n        \n        if scheduler is not None:\n            scheduler.step()\n            \n        running_loss += loss.item()\n        pred.extend(preds.view(-1).cpu().detach().numpy())\n        label.extend(labels.view(-1).cpu().detach().numpy())\n        \n        loop.set_description(f\"Epoch [{epoch+1}/{config.epochs}]\")\n        loop.set_postfix(loss=loss.item())\n\n    return running_loss/len(data_loader),acc/(len(data_loader)*config.train_batch_size)","metadata":{"execution":{"iopub.status.busy":"2022-05-05T10:08:23.175658Z","iopub.execute_input":"2022-05-05T10:08:23.176222Z","iopub.status.idle":"2022-05-05T10:08:23.188437Z","shell.execute_reply.started":"2022-05-05T10:08:23.176187Z","shell.execute_reply":"2022-05-05T10:08:23.187708Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"def valid(model, data_loader, device, epoch):\n    model.eval()\n    \n    acc = 0\n    running_loss = 0\n    pred = []\n    label = []\n\n    loop = tqdm(data_loader, position=0)\n    for spec, labels in loop:\n        spec = spec.to(device)\n        labels = labels.to(device)\n        \n        outputs = model(spec)\n        _, preds = torch.max(outputs, 1)\n        acc += (preds==labels).sum()\n        \n        loss = loss_fn(outputs, labels)\n            \n        running_loss += loss.item()\n        \n        pred.extend(preds.view(-1).cpu().detach().numpy())\n        label.extend(labels.view(-1).cpu().detach().numpy())\n        \n        loop.set_description(f\"Epoch [{epoch+1}/{config.epochs}]\")\n        loop.set_postfix(loss=loss.item())\n        \n    valid_f1 = f1_score(label, pred, average='macro')\n    \n    return running_loss/len(data_loader), valid_f1,acc/(len(data_loader)*config.valid_batch_size)","metadata":{"execution":{"iopub.status.busy":"2022-05-05T10:08:23.191183Z","iopub.execute_input":"2022-05-05T10:08:23.191460Z","iopub.status.idle":"2022-05-05T10:08:23.200978Z","shell.execute_reply.started":"2022-05-05T10:08:23.191429Z","shell.execute_reply":"2022-05-05T10:08:23.199933Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"train_dataset = BirdClefDataset(train_df)\nvalid_dataset = BirdClefDataset(valid_df)\n\ntrain_loader = torch.utils.data.DataLoader(train_dataset, batch_size=config.train_batch_size, shuffle=True,num_workers=os.cpu_count(),pin_memory=(torch.cuda.is_available()))\nvalid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=config.valid_batch_size, shuffle=True,num_workers=os.cpu_count(),pin_memory=(torch.cuda.is_available()))","metadata":{"execution":{"iopub.status.busy":"2022-05-05T10:08:23.202630Z","iopub.execute_input":"2022-05-05T10:08:23.202881Z","iopub.status.idle":"2022-05-05T10:08:23.212200Z","shell.execute_reply.started":"2022-05-05T10:08:23.202849Z","shell.execute_reply":"2022-05-05T10:08:23.211467Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"import torchvision,torch\nmodel = torchvision.models.alexnet()\nmodel.features[0] = torch.nn.Conv2d(1, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\nmodel.classifier[6] = torch.nn.Linear(in_features=4096, out_features=152, bias=True)\n\n# import torchvision.models as models\n\n# # You will need the number of filters in the `fc` for future use.\n# # Here the size of each output sample is set to 2.\n# # Alternatively, it can be generalized to nn.Linear(num_ftrs, len(class_names)).\n# model = models.resnet18(progress=True)\n# model.fc = nn.Linear(model.fc.in_features, config.num_classes) \n# model.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n\n# model.load_state_dict(torch.load('../input/alex-nex/model.pt',map_location='cpu'))\nmodel = model.to(config.device)","metadata":{"execution":{"iopub.status.busy":"2022-05-05T10:08:23.213532Z","iopub.execute_input":"2022-05-05T10:08:23.213825Z","iopub.status.idle":"2022-05-05T10:08:27.395625Z","shell.execute_reply.started":"2022-05-05T10:08:23.213790Z","shell.execute_reply":"2022-05-05T10:08:27.394902Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"from tqdm import tqdm\n \n# from transformers import Wav2Vec2Model, Wav2Vec2Config\n\n# configuration = Wav2Vec2Config(num_labels=config.num_classes)\n# model = Wav2Vec2ForSequenceClassification(configuration)\n\n\n# PATH_Model = \"../input/model-02f1\"\n# model_path = os.path.join(PATH_Model, \"model.pt\")\n# model = BirdClefModel()\n# model.load_state_dict(torch.load(model_path,map_location='cpu'))\n\n\noptimizer = torch.optim.Adam(model.parameters(), lr=5e-5)\nscheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, eta_min=1e-5, T_max=5)\n\nfor epoch in range(5):\n    train_loss,train_acc = train(model, train_loader, optimizer, scheduler, config.device, epoch)\n    valid_loss, valid_f1,valid_acc = valid(model, valid_loader, config.device, epoch)\n    print('train Loss: ',train_loss,'train_acc: ',train_acc.item(),'valid Loss: ',valid_loss,'valid_acc: ',valid_acc.item(),\" vaild_F1\",valid_f1)","metadata":{"execution":{"iopub.status.busy":"2022-05-05T13:55:48.051112Z","iopub.execute_input":"2022-05-05T13:55:48.051381Z","iopub.status.idle":"2022-05-05T15:03:16.285609Z","shell.execute_reply.started":"2022-05-05T13:55:48.051352Z","shell.execute_reply":"2022-05-05T15:03:16.284716Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stderr","text":"Epoch [1/5]: 100%|██████████| 597/597 [09:41<00:00,  1.03it/s, loss=1.39] \nEpoch [1/5]: 100%|██████████| 256/256 [03:50<00:00,  1.11it/s, loss=2.47]\n","output_type":"stream"},{"name":"stdout","text":"train Loss:  1.3411532507669586 train_acc:  0.658841073513031 valid Loss:  2.5094944811426103 valid_acc:  0.466827392578125  vaild_F1 0.29151476260665066\n","output_type":"stream"},{"name":"stderr","text":"Epoch [2/5]: 100%|██████████| 597/597 [09:33<00:00,  1.04it/s, loss=1.09] \nEpoch [2/5]: 100%|██████████| 256/256 [03:54<00:00,  1.09it/s, loss=2.56]\n","output_type":"stream"},{"name":"stdout","text":"train Loss:  1.238934044362712 train_acc:  0.6797136664390564 valid Loss:  2.547313285525888 valid_acc:  0.474090576171875  vaild_F1 0.30047273404102187\n","output_type":"stream"},{"name":"stderr","text":"Epoch [3/5]: 100%|██████████| 597/597 [09:27<00:00,  1.05it/s, loss=1.16] \nEpoch [3/5]: 100%|██████████| 256/256 [03:50<00:00,  1.11it/s, loss=2.42]\n","output_type":"stream"},{"name":"stdout","text":"train Loss:  1.1685747469290217 train_acc:  0.6983485221862793 valid Loss:  2.5634861811995506 valid_acc:  0.4747314453125  vaild_F1 0.30477544946836643\n","output_type":"stream"},{"name":"stderr","text":"Epoch [4/5]: 100%|██████████| 597/597 [09:35<00:00,  1.04it/s, loss=0.884]\nEpoch [4/5]: 100%|██████████| 256/256 [03:54<00:00,  1.09it/s, loss=2.27]\n","output_type":"stream"},{"name":"stdout","text":"train Loss:  1.1154910587585551 train_acc:  0.7075219750404358 valid Loss:  2.556160689331591 valid_acc:  0.47625732421875  vaild_F1 0.3118335439931455\n","output_type":"stream"},{"name":"stderr","text":"Epoch [5/5]: 100%|██████████| 597/597 [09:42<00:00,  1.02it/s, loss=1.31] \nEpoch [5/5]: 100%|██████████| 256/256 [03:57<00:00,  1.08it/s, loss=2.54]","output_type":"stream"},{"name":"stdout","text":"train Loss:  1.0358476760599082 train_acc:  0.7259736061096191 valid Loss:  2.5509622539393604 valid_acc:  0.478912353515625  vaild_F1 0.31593017781733423\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"model","metadata":{"execution":{"iopub.status.busy":"2022-05-05T12:33:59.461282Z","iopub.execute_input":"2022-05-05T12:33:59.461565Z","iopub.status.idle":"2022-05-05T12:33:59.469433Z","shell.execute_reply.started":"2022-05-05T12:33:59.461526Z","shell.execute_reply":"2022-05-05T12:33:59.467668Z"},"trusted":true},"execution_count":25,"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"AlexNet(\n  (features): Sequential(\n    (0): Conv2d(1, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n    (1): ReLU(inplace=True)\n    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n    (4): ReLU(inplace=True)\n    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (7): ReLU(inplace=True)\n    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (9): ReLU(inplace=True)\n    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (11): ReLU(inplace=True)\n    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n  )\n  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n  (classifier): Sequential(\n    (0): Dropout(p=0.5, inplace=False)\n    (1): Linear(in_features=9216, out_features=4096, bias=True)\n    (2): ReLU(inplace=True)\n    (3): Dropout(p=0.5, inplace=False)\n    (4): Linear(in_features=4096, out_features=4096, bias=True)\n    (5): ReLU(inplace=True)\n    (6): Linear(in_features=4096, out_features=152, bias=True)\n  )\n)"},"metadata":{}}]},{"cell_type":"code","source":"torch.save(model.state_dict(),\"model_v3.pt\")\n","metadata":{"execution":{"iopub.status.busy":"2022-05-05T15:04:41.832326Z","iopub.execute_input":"2022-05-05T15:04:41.832598Z","iopub.status.idle":"2022-05-05T15:04:42.415614Z","shell.execute_reply.started":"2022-05-05T15:04:41.832564Z","shell.execute_reply":"2022-05-05T15:04:42.414857Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}