{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2552bc4",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-05-05T16:57:40.304460Z",
     "iopub.status.busy": "2022-05-05T16:57:40.304056Z",
     "iopub.status.idle": "2022-05-05T16:57:44.296397Z",
     "shell.execute_reply": "2022-05-05T16:57:44.295313Z"
    },
    "papermill": {
     "duration": 4.00997,
     "end_time": "2022-05-05T16:57:44.298855",
     "exception": false,
     "start_time": "2022-05-05T16:57:40.288885",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../input/bird-tools')\n",
    "import noisereduce as nr\n",
    "import torch\n",
    "\n",
    "PATH_DATA = \"../input/birdclef-2022\"\n",
    "class config:\n",
    "    seed=2022\n",
    "    num_fold = 5\n",
    "    sample_rate= 32_000\n",
    "    sampleNum = 32_000*5\n",
    "    n_fft=1024\n",
    "    win_length = 1024\n",
    "    hop_length=512\n",
    "    n_mels=64\n",
    "    duration=5\n",
    "    num_classes = 152\n",
    "    learning_rate = 1e-3\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17e29fe3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-05T16:57:44.330554Z",
     "iopub.status.busy": "2022-05-05T16:57:44.329827Z",
     "iopub.status.idle": "2022-05-05T16:57:45.147680Z",
     "shell.execute_reply": "2022-05-05T16:57:45.146717Z"
    },
    "papermill": {
     "duration": 0.838105,
     "end_time": "2022-05-05T16:57:45.150257",
     "exception": false,
     "start_time": "2022-05-05T16:57:44.312152",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torchvision,torch\n",
    "model = torchvision.models.alexnet()\n",
    "model.features[0] = torch.nn.Conv2d(1, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
    "model.classifier[6] = torch.nn.Linear(in_features=4096, out_features=152, bias=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e0d0823",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-05T16:57:45.176586Z",
     "iopub.status.busy": "2022-05-05T16:57:45.176275Z",
     "iopub.status.idle": "2022-05-05T16:57:48.186861Z",
     "shell.execute_reply": "2022-05-05T16:57:48.186233Z"
    },
    "papermill": {
     "duration": 3.027642,
     "end_time": "2022-05-05T16:57:48.190266",
     "exception": false,
     "start_time": "2022-05-05T16:57:45.162624",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AlexNet(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(1, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (7): ReLU(inplace=True)\n",
      "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (9): ReLU(inplace=True)\n",
      "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
      "  (classifier): Sequential(\n",
      "    (0): Dropout(p=0.5, inplace=False)\n",
      "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Dropout(p=0.5, inplace=False)\n",
      "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): Linear(in_features=4096, out_features=152, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "PATH_Model = \"../input/alex-nex\"\n",
    "\n",
    "model_path = os.path.join(PATH_Model, \"model_v2.pt\")\n",
    "model.load_state_dict(torch.load(model_path,map_location='cpu'))\n",
    "model = model.to(config.device)\n",
    "model.eval()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aee60a04",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-05T16:57:48.218260Z",
     "iopub.status.busy": "2022-05-05T16:57:48.217767Z",
     "iopub.status.idle": "2022-05-05T16:57:48.365479Z",
     "shell.execute_reply": "2022-05-05T16:57:48.364470Z"
    },
    "papermill": {
     "duration": 0.164499,
     "end_time": "2022-05-05T16:57:48.368027",
     "exception": false,
     "start_time": "2022-05-05T16:57:48.203528",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torchaudio/functional/functional.py:433: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (128) may be set too high. Or, the value for `n_freqs` (201) may be set too low.\n",
      "  \"At least one mel filterbank has all zero values. \"\n"
     ]
    }
   ],
   "source": [
    "import noisereduce as nr\n",
    "import torchaudio\n",
    "# STFT\n",
    "device = \"cpu\"\n",
    "transform = torchaudio.transforms.MFCC(\n",
    "    sample_rate = 32000, \n",
    "    n_mfcc = 128, \n",
    "    dct_type = 2, \n",
    "    norm = 'ortho', \n",
    "    log_mels = False, \n",
    ").to(device)\n",
    "\n",
    "@torch.no_grad()\n",
    "def create_spectrogram(fname,reduce_noise = False,channel = 0):\n",
    "    waveform, sample_rate = torchaudio.load(fname)\n",
    "       \n",
    "    # Change singal to mono\n",
    "    if waveform.shape[0] > 1:\n",
    "        waveform = torch.mean(waveform, axis=0, keepdim=True)\n",
    "        \n",
    "    # Reduce noise\n",
    "    if reduce_noise:\n",
    "        waveform = torch.tensor(nr.reduce_noise(\n",
    "            y=waveform,\n",
    "            sr=sample_rate,\n",
    "            use_tqdm=True,\n",
    "            n_jobs=3,\n",
    "        ))\n",
    "    step = int(5 * sample_rate)\n",
    "    lenSamples = waveform.size()[-1]\n",
    "    if (lenSamples%step) > (step*0.6):\n",
    "        waveform = torch.nn.functional.pad(waveform, (0,step-lenSamples%step), mode='constant', value=0.0)\n",
    "    \n",
    "\n",
    "    frames = []\n",
    "    for i in range(waveform.size()[-1]//step):\n",
    "        begin = i * step\n",
    "#         print(output_path)\n",
    "        frame = waveform[:,begin:begin + step]\n",
    "        frames.append(frame)\n",
    "    return transform(torch.stack(frames)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11b444a5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-05T16:57:48.396437Z",
     "iopub.status.busy": "2022-05-05T16:57:48.395893Z",
     "iopub.status.idle": "2022-05-05T16:57:48.512662Z",
     "shell.execute_reply": "2022-05-05T16:57:48.511606Z"
    },
    "papermill": {
     "duration": 0.133813,
     "end_time": "2022-05-05T16:57:48.515095",
     "exception": false,
     "start_time": "2022-05-05T16:57:48.381282",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "df = pd.read_csv('../input/birdclef-2022/train_metadata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "01f83dbd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-05T16:57:48.543689Z",
     "iopub.status.busy": "2022-05-05T16:57:48.543401Z",
     "iopub.status.idle": "2022-05-05T16:57:48.558149Z",
     "shell.execute_reply": "2022-05-05T16:57:48.557278Z"
    },
    "papermill": {
     "duration": 0.031933,
     "end_time": "2022-05-05T16:57:48.560391",
     "exception": false,
     "start_time": "2022-05-05T16:57:48.528458",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoderList = np.load(PATH_Model+'/encoder_list.npy',allow_pickle=True)\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(encoderList)\n",
    "# encoder.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c9dfd20",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-05T16:57:48.589556Z",
     "iopub.status.busy": "2022-05-05T16:57:48.589240Z",
     "iopub.status.idle": "2022-05-05T16:57:48.599509Z",
     "shell.execute_reply": "2022-05-05T16:57:48.597825Z"
    },
    "papermill": {
     "duration": 0.027241,
     "end_time": "2022-05-05T16:57:48.601772",
     "exception": false,
     "start_time": "2022-05-05T16:57:48.574531",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['akiapo', 'aniani', 'apapan', 'barpet', 'crehon', 'elepai', 'ercfra', 'hawama', 'hawcre', 'hawgoo', 'hawhaw', 'hawpet1', 'houfin', 'iiwi', 'jabwar', 'maupar', 'omao', 'puaioh', 'skylar', 'warwhe1', 'yefcan']\n",
      "[  3   6   7   9  44  46  47  60  62  63  64  65  67  70  72  90 101 111\n",
      " 131 141 150]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open(os.path.join(PATH_DATA, \"scored_birds.json\")) as fp:\n",
    "    scored_birds = json.load(fp)\n",
    "\n",
    "print(scored_birds)\n",
    "print(encoder.transform(scored_birds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3fa53954",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-05T16:57:48.631880Z",
     "iopub.status.busy": "2022-05-05T16:57:48.631565Z",
     "iopub.status.idle": "2022-05-05T16:57:53.263766Z",
     "shell.execute_reply": "2022-05-05T16:57:53.262829Z"
    },
    "papermill": {
     "duration": 4.650043,
     "end_time": "2022-05-05T16:57:53.266000",
     "exception": false,
     "start_time": "2022-05-05T16:57:48.615957",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import math\n",
    "\n",
    "TestPathAudio = glob.glob(\"/kaggle/input/birdclef-2022/test_soundscapes/*.ogg\")\n",
    "threshold = 1/config.num_classes\n",
    "outputBirds = list(zip(scored_birds,encoder.transform(scored_birds)))\n",
    "\n",
    "submission = []\n",
    "for path_audio in TestPathAudio:\n",
    "    filename = os.path.basename(path_audio).replace('.ogg','')\n",
    "\n",
    "    spec = create_spectrogram(path_audio, reduce_noise=True).to(config.device)\n",
    "    outputs = model(spec)\n",
    "    outputs = torch.nn.Softmax(dim=1)(outputs)\n",
    "    \n",
    "    for i in range(len(outputs)):\n",
    "        for bird,pos in outputBirds:\n",
    "            submission.append({\n",
    "                \"row_id\": filename + '_'+bird +'_' + str((i+1)*5),\n",
    "                \"target\": outputs[i,pos].item() > threshold,\n",
    "            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b93b53e0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-05T16:57:53.298352Z",
     "iopub.status.busy": "2022-05-05T16:57:53.298009Z",
     "iopub.status.idle": "2022-05-05T16:57:53.316616Z",
     "shell.execute_reply": "2022-05-05T16:57:53.315971Z"
    },
    "papermill": {
     "duration": 0.036975,
     "end_time": "2022-05-05T16:57:53.318734",
     "exception": false,
     "start_time": "2022-05-05T16:57:53.281759",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_submission = pd.DataFrame(submission).set_index(\"row_id\")\n",
    "df_submission.to_csv(\"submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "73ba8dbf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-05T16:57:53.349415Z",
     "iopub.status.busy": "2022-05-05T16:57:53.348841Z",
     "iopub.status.idle": "2022-05-05T16:57:53.365291Z",
     "shell.execute_reply": "2022-05-05T16:57:53.364625Z"
    },
    "papermill": {
     "duration": 0.03362,
     "end_time": "2022-05-05T16:57:53.367218",
     "exception": false,
     "start_time": "2022-05-05T16:57:53.333598",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>row_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>soundscape_453028782_akiapo_5</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>soundscape_453028782_aniani_5</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>soundscape_453028782_apapan_5</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>soundscape_453028782_barpet_5</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>soundscape_453028782_crehon_5</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>soundscape_453028782_omao_60</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>soundscape_453028782_puaioh_60</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>soundscape_453028782_skylar_60</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>soundscape_453028782_warwhe1_60</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>soundscape_453028782_yefcan_60</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>252 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 target\n",
       "row_id                                 \n",
       "soundscape_453028782_akiapo_5     False\n",
       "soundscape_453028782_aniani_5     False\n",
       "soundscape_453028782_apapan_5     False\n",
       "soundscape_453028782_barpet_5     False\n",
       "soundscape_453028782_crehon_5     False\n",
       "...                                 ...\n",
       "soundscape_453028782_omao_60      False\n",
       "soundscape_453028782_puaioh_60    False\n",
       "soundscape_453028782_skylar_60    False\n",
       "soundscape_453028782_warwhe1_60   False\n",
       "soundscape_453028782_yefcan_60    False\n",
       "\n",
       "[252 rows x 1 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded7a17a",
   "metadata": {
    "papermill": {
     "duration": 0.014079,
     "end_time": "2022-05-05T16:57:53.395684",
     "exception": false,
     "start_time": "2022-05-05T16:57:53.381605",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 26.415623,
   "end_time": "2022-05-05T16:57:56.038648",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-05-05T16:57:29.623025",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
